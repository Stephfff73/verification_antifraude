"""
üîç IN'LI - SYST√àME EXPERT DE D√âTECTION DE FRAUDE DOCUMENTAIRE
Application Streamlit avec validation externe multi-sources
VERSION 3.0 ULTIME - Expert Anti-Fraude International
"""

import streamlit as st
import pandas as pd
from datetime import datetime
import os
import json
from pathlib import Path
import PyPDF2
from PIL import Image
import io
import re
from io import BytesIO
import base64
import requests
from geopy.distance import geodesic
import dns.resolver
from typing import Dict, List, Tuple, Optional

# Configuration de la page
st.set_page_config(
    page_title="In'li - Anti-Fraude Pro v3.0",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS professionnel am√©lior√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1e3a8a;
        text-align: center;
        padding: 1.5rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .score-box {
        padding: 25px;
        border-radius: 12px;
        text-align: center;
        font-size: 1.5rem;
        font-weight: bold;
        margin: 15px 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .score-green { background: linear-gradient(135deg, #10b981 0%, #059669 100%); color: white; }
    .score-orange { background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; }
    .score-red { background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%); color: white; }
    .score-darkred { background: linear-gradient(135deg, #991b1b 0%, #7f1d1d 100%); color: white; }
    
    .metric-card {
        background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #3b82f6;
        margin: 12px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .alert-box {
        padding: 18px;
        border-radius: 10px;
        margin: 12px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .alert-critical {
        background: linear-gradient(135deg, #fee2e2 0%, #fca5a5 100%);
        border-left: 5px solid #dc2626;
    }
    .alert-warning { 
        background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); 
        border-left: 5px solid #f59e0b; 
    }
    .alert-danger { 
        background: linear-gradient(135deg, #fee2e2 0%, #fecaca 100%); 
        border-left: 5px solid #ef4444; 
    }
    .alert-success { 
        background: linear-gradient(135deg, #d1fae5 0%, #a7f3d0 100%); 
        border-left: 5px solid #10b981; 
    }
    .info-box {
        background: #f0f9ff;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #3b82f6;
        margin: 10px 0;
    }
    .external-check {
        background: linear-gradient(135deg, #ede9fe 0%, #ddd6fe 100%);
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #8b5cf6;
        margin: 10px 0;
    }
    .stExpander {
        background-color: #f8fafc;
        border-radius: 8px;
        border: 1px solid #e2e8f0;
    }
</style>
""", unsafe_allow_html=True)

# Initialisation de la session state
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = {}
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = {}
if 'external_validations' not in st.session_state:
    st.session_state.external_validations = {}


# ======================
# APIS EXTERNES - CONFIGURATION
# ======================

API_CONFIG = {
    'insee_sirene': {
        'base_url': 'https://api.insee.fr/entreprises/sirene/V3.11',
        'enabled': True,
        'requires_key': False  # API publique
    },
    'pappers': {
        'base_url': 'https://api.pappers.fr/v2',
        'enabled': False,  # N√©cessite cl√© API (optionnel)
        'requires_key': True
    },
    'adresse_gouv': {
        'base_url': 'https://api-adresse.data.gouv.fr',
        'enabled': True,
        'requires_key': False  # API publique
    }
}


# ======================
# EXTRACTION DE DONN√âES STRUCTUR√âES
# ======================

def extract_structured_data(text: str) -> Dict:
    """Extraction intelligente de donn√©es structur√©es"""
    
    data = {
        'siret': [],
        'siren': [],
        'emails': [],
        'phones': [],
        'addresses': [],
        'amounts': [],
        'dates': [],
        'names': []
    }
    
    if not text:
        return data
    
    # SIRET (14 chiffres)
    siret_matches = re.findall(r'\b\d{3}\s?\d{3}\s?\d{3}\s?\d{5}\b', text)
    data['siret'] = [s.replace(' ', '') for s in siret_matches]
    
    # SIREN (9 chiffres)
    siren_matches = re.findall(r'\b\d{3}\s?\d{3}\s?\d{3}\b', text)
    data['siren'] = [s.replace(' ', '') for s in siren_matches if len(s.replace(' ', '')) == 9]
    
    # Emails
    data['emails'] = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text)
    
    # T√©l√©phones fran√ßais
    data['phones'] = re.findall(r'(?:(?:\+|00)33|0)\s*[1-9](?:[\s.-]*\d{2}){4}', text)
    
    # Montants
    data['amounts'] = extract_amounts_with_context(text)
    
    # Dates
    data['dates'] = re.findall(r'\b\d{1,2}[/\.]\d{1,2}[/\.]\d{4}\b', text)
    
    # Noms propres (majuscules)
    data['names'] = re.findall(r'\b[A-Z√â√à][a-z√©√®√™√†√ß]+(?:\s+[A-Z√â√à][a-z√©√®√™√†√ß]+)+\b', text)
    
    # Adresses (pattern simplifi√©)
    data['addresses'] = extract_addresses(text)
    
    return data


def extract_amounts_with_context(text: str) -> List[Dict]:
    """Extraction de montants avec leur contexte"""
    amounts = []
    
    patterns = [
        (r'(?:salaire|net|brut|imposable)[\s:]+(\d+[\s\.]?\d*[,\.]\d{2})', 'salaire'),
        (r'(?:loyer|charges)[\s:]+(\d+[\s\.]?\d*[,\.]\d{2})', 'loyer'),
        (r'(?:revenu|revenus)[\s:]+(\d+[\s\.]?\d*[,\.]\d{2})', 'revenu'),
    ]
    
    for pattern, category in patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE)
        for match in matches:
            amount_str = match.group(1).replace(' ', '').replace('.', '').replace(',', '.')
            try:
                amount = float(amount_str)
                amounts.append({
                    'value': amount,
                    'category': category,
                    'context': match.group(0)
                })
            except:
                pass
    
    return amounts


def extract_addresses(text: str) -> List[str]:
    """Extraction d'adresses fran√ßaises"""
    # Pattern simplifi√© pour adresses
    # Cherche : num√©ro + rue/avenue/boulevard + code postal + ville
    address_pattern = r'\d+[,\s]+(?:rue|avenue|boulevard|place|all√©e|chemin)[^,\n]+,?\s*\d{5}\s+[A-Z√â√à][a-z√©√®√™√†√ß\s-]+'
    
    addresses = re.findall(address_pattern, text, re.IGNORECASE)
    
    return [addr.strip() for addr in addresses]


# ======================
# API EXTERNE 1 : VALIDATION SIRET (INSEE)
# ======================

def validate_siret_insee(siret: str) -> Dict:
    """
    Validation SIRET via API INSEE SIRENE
    
    √âTAPES D'UTILISATION :
    1. Pas besoin de cl√© API (service public)
    2. Retourne : raison sociale, adresse, statut, date cr√©ation
    3. D√©tecte si entreprise active ou radi√©e
    """
    
    result = {
        'valid': False,
        'exists': False,
        'company_name': None,
        'address': None,
        'status': None,
        'creation_date': None,
        'activity': None,
        'error': None,
        'api_used': 'INSEE SIRENE'
    }
    
    if not siret or len(siret) != 14:
        result['error'] = "SIRET invalide (doit contenir 14 chiffres)"
        return result
    
    try:
        # API INSEE SIRENE v3.11 (publique)
        url = f"https://api.insee.fr/entreprises/sirene/V3.11/siret/{siret}"
        
        # Appel sans authentification (donn√©es publiques)
        response = requests.get(
            url,
            headers={'Accept': 'application/json'},
            timeout=5
        )
        
        if response.status_code == 200:
            data = response.json()
            
            if 'etablissement' in data:
                etab = data['etablissement']
                
                result['valid'] = True
                result['exists'] = True
                
                # Extraction des donn√©es
                result['company_name'] = etab.get('uniteLegale', {}).get('denominationUniteLegale', 'Non renseign√©')
                
                # Adresse
                adresse_etab = etab.get('adresseEtablissement', {})
                result['address'] = f"{adresse_etab.get('numeroVoieEtablissement', '')} {adresse_etab.get('typeVoieEtablissement', '')} {adresse_etab.get('libelleVoieEtablissement', '')}, {adresse_etab.get('codePostalEtablissement', '')} {adresse_etab.get('libelleCommuneEtablissement', '')}"
                
                # Statut
                periode_etab = etab.get('periodesEtablissement', [{}])[0]
                etat = periode_etab.get('etatAdministratifEtablissement', 'A')
                result['status'] = 'Active' if etat == 'A' else 'Ferm√©e'
                
                # Date cr√©ation
                result['creation_date'] = etab.get('dateCreationEtablissement', 'Non renseign√©e')
                
                # Activit√©
                result['activity'] = etab.get('uniteLegale', {}).get('activitePrincipaleUniteLegale', 'Non renseign√©e')
                
        elif response.status_code == 404:
            result['error'] = "SIRET introuvable dans la base INSEE"
        else:
            result['error'] = f"Erreur API INSEE (code {response.status_code})"
            
    except requests.Timeout:
        result['error'] = "Timeout - API INSEE non accessible"
    except Exception as e:
        result['error'] = f"Erreur technique : {str(e)}"
    
    return result


# ======================
# API EXTERNE 2 : VALIDATION ADRESSE (DATA.GOUV)
# ======================

def validate_address_gouv(address: str) -> Dict:
    """
    Validation adresse via API Adresse Data.gouv.fr
    
    √âTAPES D'UTILISATION :
    1. Gratuit et illimit√©
    2. Normalise l'adresse
    3. Retourne coordonn√©es GPS pour calcul distances
    4. Score de confiance 0-1
    """
    
    result = {
        'valid': False,
        'normalized_address': None,
        'latitude': None,
        'longitude': None,
        'confidence_score': 0,
        'city': None,
        'postal_code': None,
        'error': None,
        'api_used': 'API Adresse Data.gouv'
    }
    
    if not address or len(address) < 5:
        result['error'] = "Adresse trop courte"
        return result
    
    try:
        url = "https://api-adresse.data.gouv.fr/search/"
        
        response = requests.get(
            url,
            params={'q': address, 'limit': 1},
            timeout=5
        )
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get('features'):
                feature = data['features'][0]
                properties = feature['properties']
                geometry = feature['geometry']
                
                result['valid'] = True
                result['normalized_address'] = properties.get('label', address)
                result['confidence_score'] = properties.get('score', 0)
                result['city'] = properties.get('city', '')
                result['postal_code'] = properties.get('postcode', '')
                
                # Coordonn√©es GPS
                if geometry and geometry.get('coordinates'):
                    result['longitude'] = geometry['coordinates'][0]
                    result['latitude'] = geometry['coordinates'][1]
            else:
                result['error'] = "Adresse introuvable"
        else:
            result['error'] = f"Erreur API (code {response.status_code})"
            
    except requests.Timeout:
        result['error'] = "Timeout - API Adresse non accessible"
    except Exception as e:
        result['error'] = f"Erreur technique : {str(e)}"
    
    return result


# ======================
# API EXTERNE 3 : VALIDATION EMAIL
# ======================

def validate_email_advanced(email: str) -> Dict:
    """
    Validation email avec v√©rification DNS
    
    √âTAPES :
    1. V√©rification format (regex)
    2. Extraction domaine
    3. V√©rification DNS MX (serveur mail existe ?)
    4. D√©tection domaines jetables/suspects
    """
    
    result = {
        'valid': False,
        'format_valid': False,
        'domain_valid': False,
        'disposable': False,
        'domain': None,
        'confidence': 0,
        'warnings': []
    }
    
    if not email:
        result['warnings'].append("Email manquant")
        return result
    
    # 1. Validation format
    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    if re.match(email_pattern, email):
        result['format_valid'] = True
    else:
        result['warnings'].append("Format email invalide")
        return result
    
    # 2. Extraction domaine
    domain = email.split('@')[1]
    result['domain'] = domain
    
    # 3. Domaines jetables connus
    disposable_domains = [
        'yopmail.com', 'tempmail.com', 'guerrillamail.com', 
        'mailinator.com', '10minutemail.com', 'throwaway.email'
    ]
    
    if domain.lower() in disposable_domains:
        result['disposable'] = True
        result['warnings'].append("Email jetable d√©tect√©")
        return result
    
    # 4. V√©rification DNS MX
    try:
        mx_records = dns.resolver.resolve(domain, 'MX')
        if mx_records:
            result['domain_valid'] = True
            result['valid'] = True
            result['confidence'] = 0.9
        else:
            result['warnings'].append("Pas de serveur mail configur√©")
    except dns.resolver.NXDOMAIN:
        result['warnings'].append("Domaine inexistant")
    except dns.resolver.NoAnswer:
        result['warnings'].append("Pas d'enregistrement MX")
    except Exception as e:
        result['warnings'].append(f"V√©rification DNS impossible : {str(e)}")
        # On consid√®re valide par d√©faut si DNS √©choue
        result['valid'] = True
        result['confidence'] = 0.5
    
    return result


# ======================
# CALCUL DISTANCE G√âOGRAPHIQUE
# ======================

def calculate_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> Optional[float]:
    """Calcule la distance en km entre 2 points GPS"""
    try:
        distance = geodesic((lat1, lon1), (lat2, lon2)).kilometers
        return round(distance, 1)
    except:
        return None


# ======================
# D√âTECTEUR DE RED FLAGS EXPERT
# ======================

def detect_red_flags(documents_data: Dict, structured_data: Dict, external_validations: Dict) -> List[Dict]:
    """
    D√©tection de 15+ signaux d'alerte bas√©s sur 40 ans d'expertise
    """
    
    red_flags = []
    
    # 1. Entreprise r√©cente avec salaires √©lev√©s
    if 'siret_validation' in external_validations:
        siret_info = external_validations['siret_validation']
        if siret_info and siret_info.get('exists') and siret_info.get('creation_date'):
            try:
                creation_year = int(siret_info['creation_date'][:4])
                current_year = datetime.now().year
                
                if current_year - creation_year < 1:
                    # Extraire salaires
                    salaries = []
                    for doc_key, data in structured_data.items():
                        if 'fiche_paie' in doc_key:
                            amounts = data.get('amounts', [])
                            for amt in amounts:
                                if amt['category'] == 'salaire':
                                    salaries.append(amt['value'])
                    
                    if salaries and max(salaries) > 3500:
                        red_flags.append({
                            'severity': 'high',
                            'category': 'Entreprise',
                            'message': f"üö® Entreprise cr√©√©e r√©cemment ({creation_year}) avec salaire √©lev√© ({max(salaries):.0f}‚Ç¨) - Suspect",
                            'score_impact': 25
                        })
            except:
                pass
    
    # 2. Adresse domicile = adresse entreprise
    domicile_addresses = []
    company_addresses = []
    
    for doc_key, data in structured_data.items():
        if 'piece_identite' in doc_key or 'quittance' in doc_key:
            domicile_addresses.extend(data.get('addresses', []))
        if 'contrat_travail' in doc_key or 'fiche_paie' in doc_key:
            company_addresses.extend(data.get('addresses', []))
    
    # Comparaison simplifi√©e
    for dom in domicile_addresses:
        for comp in company_addresses:
            if len(dom) > 10 and len(comp) > 10:
                # Similarit√© basique
                dom_normalized = dom.lower().replace(' ', '')
                comp_normalized = comp.lower().replace(' ', '')
                
                if dom_normalized in comp_normalized or comp_normalized in dom_normalized:
                    red_flags.append({
                        'severity': 'critical',
                        'category': 'Adresse',
                        'message': f"üö® ALERTE MAJEURE : Adresse domicile identique √† l'entreprise - Fraude probable",
                        'score_impact': 40
                    })
    
    # 3. Email gratuit pour poste cadre
    for doc_key, data in structured_data.items():
        emails = data.get('emails', [])
        text = documents_data.get(doc_key, {}).get('text_extract', '').lower()
        
        # D√©tection poste cadre
        if any(word in text for word in ['cadre', 'directeur', 'manager', 'responsable']):
            for email in emails:
                if any(domain in email.lower() for domain in ['@gmail.', '@yahoo.', '@hotmail.', '@outlook.']):
                    red_flags.append({
                        'severity': 'medium',
                        'category': 'Email',
                        'message': f"‚ö†Ô∏è Email gratuit ({email}) pour poste cadre - Inhabituel",
                        'score_impact': 15
                    })
    
    # 4. Distance domicile-travail excessive
    if 'address_home' in external_validations and 'address_work' in external_validations:
        home = external_validations['address_home']
        work = external_validations['address_work']
        
        if home and work and home.get('latitude') and work.get('latitude'):
            distance = calculate_distance(
                home['latitude'], home['longitude'],
                work['latitude'], work['longitude']
            )
            
            if distance and distance > 200:
                red_flags.append({
                    'severity': 'medium',
                    'category': 'G√©ographie',
                    'message': f"‚ö†Ô∏è Distance domicile-travail importante ({distance} km) - V√©rifier t√©l√©travail",
                    'score_impact': 10
                })
    # 5. Incoh√©rence salaire d√©clar√© vs revenus imposables
    salaries = []
    revenus = []
    
    for doc_key, data in structured_data.items():
        amounts = data.get('amounts', [])
        for amt in amounts:
            if amt['category'] == 'salaire':
                salaries.append(amt['value'])
            elif amt['category'] == 'revenu':
                revenus.append(amt['value'])
    
    if salaries and revenus:
        monthly_salary = max(salaries)
        annual_revenue = max(revenus)
        expected_annual = monthly_salary * 12
        
        deviation = abs(expected_annual - annual_revenue) / expected_annual * 100
        
        if deviation > 30:
            red_flags.append({
                'severity': 'critical',
                'category': 'Revenus',
                'message': f"üö® Incoh√©rence MAJEURE : Salaire mensuel ({monthly_salary:.0f}‚Ç¨) vs Revenu annuel ({annual_revenue:.0f}‚Ç¨) - √âcart {deviation:.0f}%",
                'score_impact': 35
            })
    
    # 6. Entreprise radi√©e/ferm√©e
    if 'siret_validation' in external_validations:
        siret_info = external_validations['siret_validation']
        if siret_info and siret_info.get('status') == 'Ferm√©e':
            red_flags.append({
                'severity': 'critical',
                'category': 'Entreprise',
                'message': "üö® FRAUDE CONFIRM√âE : Entreprise ferm√©e/radi√©e selon INSEE",
                'score_impact': 50
            })
    
    # 7. Salaire anormalement √©lev√© pour le secteur
    # (N√©cessiterait une base de donn√©es des salaires moyens par secteur)
    # Simplifi√© : d√©tection salaires > 10k‚Ç¨/mois
    if salaries and max(salaries) > 10000:
        red_flags.append({
            'severity': 'high',
            'category': 'Salaire',
            'message': f"üö® Salaire tr√®s √©lev√© ({max(salaries):.0f}‚Ç¨/mois) - V√©rification approfondie requise",
            'score_impact': 20
        })
    
    # 8. Aucun SIRET trouv√© dans les documents
    all_sirets = []
    for data in structured_data.values():
        all_sirets.extend(data.get('siret', []))
    
    if not all_sirets:
        red_flags.append({
            'severity': 'high',
            'category': 'Entreprise',
            'message': "‚ö†Ô∏è Aucun SIRET d√©tect√© dans les documents - Document incomplet ou suspect",
            'score_impact': 25
        })
    
    return red_flags


# ======================
# ORCHESTRATION VALIDATION EXTERNE
# ======================

def perform_external_validations(documents_data: Dict, structured_data: Dict) -> Dict:
    """
    Orchestre toutes les validations externes
    """
    
    validations = {
        'siret_validation': None,
        'address_home': None,
        'address_work': None,
        'email_validation': None,
        'geographic_check': None,
        'red_flags': []
    }
    
    # 1. Validation SIRET (premier trouv√©)
    all_sirets = []
    for data in structured_data.values():
        all_sirets.extend(data.get('siret', []))
    
    if all_sirets:
        # Prendre le premier SIRET unique
        unique_sirets = list(set(all_sirets))
        validations['siret_validation'] = validate_siret_insee(unique_sirets[0])
    
    # 2. Validation adresses
    # Adresse domicile (chercher dans pi√®ce identit√© / quittances)
    domicile_addresses = []
    for doc_key, data in structured_data.items():
        if 'piece_identite' in doc_key or 'quittance' in doc_key:
            domicile_addresses.extend(data.get('addresses', []))
    
    if domicile_addresses:
        validations['address_home'] = validate_address_gouv(domicile_addresses[0])
    
    # Adresse entreprise (chercher dans contrat / fiche paie)
    work_addresses = []
    for doc_key, data in structured_data.items():
        if 'contrat_travail' in doc_key or 'fiche_paie' in doc_key:
            work_addresses.extend(data.get('addresses', []))
    
    if work_addresses:
        validations['address_work'] = validate_address_gouv(work_addresses[0])
    
    # 3. Calcul distance si les deux adresses sont valid√©es
    if (validations['address_home'] and validations['address_home'].get('latitude') and
        validations['address_work'] and validations['address_work'].get('latitude')):
        
        distance = calculate_distance(
            validations['address_home']['latitude'],
            validations['address_home']['longitude'],
            validations['address_work']['latitude'],
            validations['address_work']['longitude']
        )
        
        validations['geographic_check'] = {
            'distance_km': distance,
            'reasonable': distance < 100 if distance else None
        }
    
    # 4. Validation email (premier trouv√©)
    all_emails = []
    for data in structured_data.values():
        all_emails.extend(data.get('emails', []))
    
    if all_emails:
        unique_emails = list(set(all_emails))
        validations['email_validation'] = validate_email_advanced(unique_emails[0])
    
    # 5. D√©tection Red Flags
    validations['red_flags'] = detect_red_flags(documents_data, structured_data, validations)
    
    return validations


# ======================
# FONCTIONS D'ANALYSE DOCUMENT (Version pr√©c√©dente conserv√©e)
# ======================

def analyze_pdf_metadata_advanced(pdf_file):
    """Analyse approfondie des m√©tadonn√©es PDF avec d√©tection de fraude"""
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        metadata = pdf_reader.metadata
        
        suspicious_signs = []
        risk_score = 0
        
        creator = str(metadata.get('/Creator', '')) if metadata else ''
        producer = str(metadata.get('/Producer', '')) if metadata else ''
        
        suspicious_editors = [
            'photoshop', 'gimp', 'canva', 'pixlr', 'paint.net',
            'online', 'edit', 'pdf-editor', 'smallpdf', 'ilovepdf',
            'sodapdf', 'pdfforge', 'nitro', 'foxit-edit', 'sejda'
        ]
        
        creator_lower = creator.lower()
        producer_lower = producer.lower()
        
        if any(editor in creator_lower for editor in suspicious_editors):
            suspicious_signs.append(f"‚ö†Ô∏è Cr√©ateur suspect : {creator}")
            risk_score += 30
        
        if any(editor in producer_lower for editor in suspicious_editors):
            suspicious_signs.append(f"‚ö†Ô∏è Producteur suspect : {producer}")
            risk_score += 25
        
        creation_date = str(metadata.get('/CreationDate', '')) if metadata else ''
        mod_date = str(metadata.get('/ModDate', '')) if metadata else ''
        
        if creation_date:
            try:
                if creation_date.startswith('D:'):
                    date_str = creation_date[2:10]
                    doc_year = int(date_str[:4])
                    current_year = datetime.now().year
                    
                    if current_year - doc_year < 1:
                        suspicious_signs.append(f"üìÖ Document cr√©√© r√©cemment ({doc_year})")
                        risk_score += 15
            except:
                pass
        
        if creation_date and mod_date and creation_date != mod_date:
            suspicious_signs.append("‚úèÔ∏è Document modifi√© apr√®s cr√©ation")
            risk_score += 10
        
        num_pages = len(pdf_reader.pages)
        
        if num_pages > 10:
            suspicious_signs.append(f"üìÑ Nombre de pages inhabituel : {num_pages}")
            risk_score += 5
        
        return {
            'creator': creator or 'Non sp√©cifi√©',
            'producer': producer or 'Non sp√©cifi√©',
            'creation_date': format_pdf_date(creation_date) if creation_date else 'Non sp√©cifi√©e',
            'modification_date': format_pdf_date(mod_date) if mod_date else 'Non sp√©cifi√©e',
            'num_pages': num_pages,
            'suspicious_signs': suspicious_signs,
            'risk_score': min(risk_score, 100)
        }
    except Exception as e:
        return {
            'creator': 'Erreur',
            'producer': 'Erreur',
            'creation_date': 'Non disponible',
            'modification_date': 'Non disponible',
            'num_pages': 0,
            'suspicious_signs': [f"‚ùå Erreur d'analyse : {str(e)}"],
            'risk_score': 50
        }


def format_pdf_date(pdf_date_string):
    """Convertit une date PDF au format lisible"""
    try:
        if pdf_date_string.startswith('D:'):
            date_str = pdf_date_string[2:14]
            year = date_str[0:4]
            month = date_str[4:6]
            day = date_str[6:8]
            hour = date_str[8:10]
            minute = date_str[10:12]
            return f"{day}/{month}/{year} √† {hour}h{minute}"
        return pdf_date_string
    except:
        return pdf_date_string


def extract_text_from_pdf_advanced(pdf_file):
    """Extraction de texte avanc√©e avec nettoyage"""
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        
        for page_num, page in enumerate(pdf_reader.pages, 1):
            page_text = page.extract_text()
            if page_text:
                text += f"\n--- Page {page_num} ---\n{page_text}\n"
        
        text = text.strip()
        
        if len(text) < 20:
            return None, "‚ö†Ô∏è Peu ou pas de texte extractible - Document probablement scann√© ou image"
        
        return text, None
        
    except Exception as e:
        return None, f"‚ùå Erreur d'extraction : {str(e)}"


def extract_text_from_image(image_file):
    """Simulation OCR basique pour les images"""
    try:
        img = Image.open(image_file)
        width, height = img.size
        
        return None, f"üì∑ Image d√©tect√©e ({width}x{height}px) - OCR n√©cessite installation Tesseract"
        
    except Exception as e:
        return None, f"‚ùå Erreur de lecture image : {str(e)}"


def validate_document_professional(doc_type, metadata, text_content):
    """Validation professionnelle avanc√©e avec d√©tection multi-crit√®res"""
    score_fraude = 0
    anomalies = []
    checks = {}
    
    metadata_risk = metadata.get('risk_score', 0)
    score_fraude += metadata_risk * 0.4
    
    if metadata.get('suspicious_signs'):
        anomalies.extend(metadata['suspicious_signs'])
    
    if not text_content or len(text_content) < 50:
        score_fraude += 30
        anomalies.append("‚ö†Ô∏è Texte non extractible - Document image ou scan de mauvaise qualit√©")
        checks['text_extractable'] = False
    else:
        checks['text_extractable'] = True
        
        text_lower = text_content.lower()
        
        if doc_type.startswith('fiche_paie'):
            checks_paie = validate_fiche_paie(text_lower)
            checks.update(checks_paie['checks'])
            anomalies.extend(checks_paie['anomalies'])
            score_fraude += checks_paie['score']
        
        elif doc_type == 'contrat_travail':
            checks_contrat = validate_contrat_travail(text_lower)
            checks.update(checks_contrat['checks'])
            anomalies.extend(checks_contrat['anomalies'])
            score_fraude += checks_contrat['score']
        
        elif doc_type == 'avis_imposition':
            checks_impots = validate_avis_imposition(text_lower)
            checks.update(checks_impots['checks'])
            anomalies.extend(checks_impots['anomalies'])
            score_fraude += checks_impots['score']
        
        elif doc_type == 'piece_identite':
            checks_id = validate_piece_identite(text_lower, text_content)
            checks.update(checks_id['checks'])
            anomalies.extend(checks_id['anomalies'])
            score_fraude += checks_id['score']
        
        elif doc_type.startswith('quittance'):
            checks_quittance = validate_quittance_loyer(text_lower)
            checks.update(checks_quittance['checks'])
            anomalies.extend(checks_quittance['anomalies'])
            score_fraude += checks_quittance['score']
    
    score_fraude = min(score_fraude, 100)
    
    return {
        'score_fraude': score_fraude / 100,
        'anomalies': anomalies,
        'checks': checks,
        'risk_level': get_risk_level(score_fraude)
    }


def validate_fiche_paie(text):
    """Validation sp√©cifique fiche de paie"""
    score = 0
    anomalies = []
    checks = {}
    
    keywords_required = ['salaire', 'brut', 'net', 'cotisation']
    keywords_found = sum(1 for kw in keywords_required if kw in text)
    
    checks['contains_salary_keywords'] = keywords_found >= 2
    
    if keywords_found < 2:
        score += 35
        anomalies.append(f"‚ùå Fiche de paie incompl√®te - Seulement {keywords_found}/4 mots-cl√©s trouv√©s")
    
    if 'urssaf' not in text and 'siren' not in text and 'siret' not in text:
        score += 20
        anomalies.append("‚ö†Ô∏è Absence de r√©f√©rences URSSAF/SIREN/SIRET")
        checks['has_company_identifiers'] = False
    else:
        checks['has_company_identifiers'] = True
    
    if not re.search(r'\d+[,\.]\d{2}', text):
        score += 15
        anomalies.append("‚ö†Ô∏è Aucun montant au format mon√©taire d√©tect√©")
        checks['has_amounts'] = False
    else:
        checks['has_amounts'] = True
    
    return {'score': score, 'anomalies': anomalies, 'checks': checks}


def validate_contrat_travail(text):
    """Validation sp√©cifique contrat de travail"""
    score = 0
    anomalies = []
    checks = {}
    
    keywords = ['contrat', 'travail', 'employeur', 'salari√©', 'dur√©e']
    keywords_found = sum(1 for kw in keywords if kw in text)
    
    checks['contains_contract_keywords'] = keywords_found >= 3
    
    if keywords_found < 3:
        score += 30
        anomalies.append(f"‚ùå Contrat incomplet - {keywords_found}/5 mots-cl√©s trouv√©s")
    
    if 'cdi' not in text and 'cdd' not in text and 'int√©rim' not in text:
        score += 15
        anomalies.append("‚ö†Ô∏è Type de contrat non identifiable")
        checks['has_contract_type'] = False
    else:
        checks['has_contract_type'] = True
    
    if 'signature' not in text and 'sign√©' not in text:
        score += 10
        anomalies.append("‚ö†Ô∏è Aucune mention de signature")
        checks['has_signature_mention'] = False
    else:
        checks['has_signature_mention'] = True
    
    return {'score': score, 'anomalies': anomalies, 'checks': checks}


def validate_avis_imposition(text):
    """Validation sp√©cifique avis d'imposition"""
    score = 0
    anomalies = []
    checks = {}
    
    keywords = ['imp√¥t', 'revenu', 'fiscal', 'dgfip', 'finances publiques']
    keywords_found = sum(1 for kw in keywords if kw in text)
    
    checks['contains_tax_keywords'] = keywords_found >= 2
    
    if keywords_found < 2:
        score += 35
        anomalies.append(f"‚ùå Avis d'imposition suspect - {keywords_found}/5 mots-cl√©s trouv√©s")
    
    if 'num√©ro fiscal' not in text and 'n¬∞ fiscal' not in text:
        score += 20
        anomalies.append("‚ö†Ô∏è Absence de num√©ro fiscal")
        checks['has_fiscal_number'] = False
    else:
        checks['has_fiscal_number'] = True
    
    if 'r√©f√©rence' not in text and 'avis' not in text:
        score += 15
        anomalies.append("‚ö†Ô∏è Absence de r√©f√©rence d'avis")
        checks['has_reference'] = False
    else:
        checks['has_reference'] = True
    
    return {'score': score, 'anomalies': anomalies, 'checks': checks}


def validate_piece_identite(text_lower, text_original):
    """Validation sp√©cifique pi√®ce d'identit√©"""
    score = 0
    anomalies = []
    checks = {}
    
    doc_types = ['carte nationale', 'identit√©', 'passeport', 'permis', 'conduire']
    has_id_type = any(doc_type in text_lower for doc_type in doc_types)
    
    checks['has_id_type'] = has_id_type
    
    if not has_id_type:
        score += 40
        anomalies.append("‚ùå Type de pi√®ce d'identit√© non identifiable")
    
    has_birthdate = bool(re.search(r'\d{2}[/\.]\d{2}[/\.]\d{4}', text_original))
    checks['has_birthdate_pattern'] = has_birthdate
    
    if not has_birthdate:
        score += 15
        anomalies.append("‚ö†Ô∏è Aucune date au format standard d√©tect√©e")
    
    if 'r√©publique' in text_lower and 'fran√ßaise' in text_lower:
        checks['has_republic_mention'] = True
    else:
        checks['has_republic_mention'] = False
        score += 20
        anomalies.append("‚ö†Ô∏è Absence de mention 'R√©publique Fran√ßaise'")
    
    has_numbers = bool(re.search(r'\d{6,}', text_original))
    checks['has_document_numbers'] = has_numbers
    
    if not has_numbers:
        score += 10
        anomalies.append("‚ö†Ô∏è Absence de num√©ros de document")
    
    return {'score': score, 'anomalies': anomalies, 'checks': checks}


def validate_quittance_loyer(text):
    """Validation sp√©cifique quittance de loyer"""
    score = 0
    anomalies = []
    checks = {}
    
    keywords = ['quittance', 'loyer', 'locataire', 'propri√©taire', 'bail']
    keywords_found = sum(1 for kw in keywords if kw in text)
    
    checks['contains_rent_keywords'] = keywords_found >= 2
    
    if keywords_found < 2:
        score += 30
        anomalies.append(f"‚ùå Quittance incompl√®te - {keywords_found}/5 mots-cl√©s trouv√©s")
    
    months = ['janvier', 'f√©vrier', 'mars', 'avril', 'mai', 'juin', 
              'juillet', 'ao√ªt', 'septembre', 'octobre', 'novembre', 'd√©cembre']
    has_period = any(month in text for month in months)
    
    checks['has_period'] = has_period
    
    if not has_period:
        score += 20
        anomalies.append("‚ö†Ô∏è P√©riode de location non identifiable")
    
    if not re.search(r'\d+[,\.]\d{2}', text):
        score += 15
        anomalies.append("‚ö†Ô∏è Aucun montant d√©tect√©")
        checks['has_amounts'] = False
    else:
        checks['has_amounts'] = True
    
    return {'score': score, 'anomalies': anomalies, 'checks': checks}


def cross_validate_dossier_advanced(documents_data, structured_data):
    """Validation crois√©e avanc√©e entre documents"""
    anomalies = []
    checks = {}
    
    # V√©rification coh√©rence fiches de paie
    paie_docs = [k for k in documents_data.keys() if k.startswith('fiche_paie')]
    
    if len(paie_docs) >= 2:
        checks['has_multiple_payslips'] = True
        
        paie_amounts = []
        for doc in paie_docs:
            if doc in structured_data:
                amounts = structured_data[doc].get('amounts', [])
                for amt in amounts:
                    if amt['category'] == 'salaire' and amt['value'] > 1000:
                        paie_amounts.append(amt['value'])
        
        if len(paie_amounts) >= 2:
            max_amount = max(paie_amounts)
            min_amount = min(paie_amounts)
            variation = ((max_amount - min_amount) / min_amount) * 100
            
            if variation > 50:
                anomalies.append(f"‚ö†Ô∏è Variation importante entre fiches de paie : {variation:.1f}%")
                checks['consistent_salaries'] = False
            else:
                checks['consistent_salaries'] = True
        else:
            checks['consistent_salaries'] = None
    else:
        checks['has_multiple_payslips'] = False
        anomalies.append("‚ö†Ô∏è Moins de 2 fiches de paie fournies")
    
    required_docs = ['contrat_travail', 'fiche_paie_1', 'avis_imposition', 'piece_identite']
    missing_docs = [doc for doc in required_docs if doc not in documents_data]
    
    if missing_docs:
        checks['all_required_docs'] = False
        anomalies.append(f"‚ö†Ô∏è Documents manquants : {', '.join(missing_docs)}")
    else:
        checks['all_required_docs'] = True
    
    if 'fiche_paie_1' in documents_data and 'avis_imposition' in documents_data:
        checks['can_cross_check_income'] = True
    else:
        checks['can_cross_check_income'] = False
        anomalies.append("‚ö†Ô∏è Impossible de croiser les revenus (documents manquants)")
    
    if 'piece_identite' in documents_data:
        checks['identity_provided'] = True
    else:
        checks['identity_provided'] = False
        anomalies.append("‚ö†Ô∏è Pi√®ce d'identit√© manquante")
    
    return {
        'checks': checks,
        'anomalies': anomalies
    }


def calculate_global_score(documents_data, cross_validation, external_validations):
    """Calcule le score global avec pond√©ration incluant validations externes"""
    
    # 1. Score documents (40%)
    doc_scores = []
    for doc_data in documents_data.values():
        validation = doc_data.get('validation', {})
        doc_scores.append(validation.get('score_fraude', 0))
    
    avg_doc_score = sum(doc_scores) / len(doc_scores) if doc_scores else 0.5
    
    # 2. Score validation crois√©e (30%)
    cross_checks = cross_validation.get('checks', {})
    cross_anomalies = len(cross_validation.get('anomalies', []))
    
    failed_checks = sum(1 for v in cross_checks.values() if v is False)
    cross_penalty = (failed_checks * 0.1) + (cross_anomalies * 0.05)
    
    # 3. Score RED FLAGS (30%)
    red_flags = external_validations.get('red_flags', [])
    red_flag_score = sum(flag['score_impact'] for flag in red_flags) / 100
    red_flag_score = min(red_flag_score, 1.0)
    
    # Score final pond√©r√©
    final_score = (avg_doc_score * 0.4 + cross_penalty * 0.3 + red_flag_score * 0.3) * 100
    final_score = min(final_score, 100)
    
    # Verdict
    if final_score < 15:
        verdict = "‚úÖ DOSSIER FIABLE"
        color = "green"
        recommendation = "Dossier valid√© - Risque tr√®s faible"
        action = "APPROUVER"
    elif final_score < 30:
        verdict = "‚úÖ DOSSIER ACCEPTABLE"
        color = "green"
        recommendation = "Dossier acceptable - Risque faible"
        action = "APPROUVER avec vigilance"
    elif final_score < 50:
        verdict = "‚ö†Ô∏è VIGILANCE REQUISE"
        color = "orange"
        recommendation = "V√©rifications compl√©mentaires recommand√©es"
        action = "V√âRIFIER manuellement"
    elif final_score < 70:
        verdict = "üî¥ SUSPICION DE FRAUDE"
        color = "red"
        recommendation = "Risque √©lev√© - Audit approfondi n√©cessaire"
        action = "CONTACTER le candidat"
    else:
        verdict = "üö® FRAUDE PROBABLE"
        color = "darkred"
        recommendation = "Risque tr√®s √©lev√© - Rejet recommand√©"
        action = "REJETER le dossier"
    
    return {
        'score': final_score,
        'verdict': verdict,
        'color': color,
        'recommendation': recommendation,
        'action': action,
        'doc_score_contribution': avg_doc_score * 40,
        'cross_validation_penalty': cross_penalty * 30,
        'red_flags_penalty': red_flag_score * 30
    }


def get_risk_level(score):
    """Retourne le niveau de risque textuel"""
    if score < 15:
        return "Tr√®s faible"
    elif score < 30:
        return "Faible"
    elif score < 50:
        return "Mod√©r√©"
    elif score < 70:
        return "√âlev√©"
    else:
        return "Tr√®s √©lev√©"


def format_metadata_for_display(metadata):
    """Formate les m√©tadonn√©es pour affichage texte lisible"""
    lines = []
    lines.append("üìÑ **M√âTADONN√âES DU DOCUMENT**")
    lines.append("")
    lines.append(f"‚Ä¢ **Cr√©ateur** : {metadata.get('creator', 'Non sp√©cifi√©')}")
    lines.append(f"‚Ä¢ **Producteur** : {metadata.get('producer', 'Non sp√©cifi√©')}")
    lines.append(f"‚Ä¢ **Date de cr√©ation** : {metadata.get('creation_date', 'Non sp√©cifi√©e')}")
    lines.append(f"‚Ä¢ **Date de modification** : {metadata.get('modification_date', 'Non sp√©cifi√©e')}")
    lines.append(f"‚Ä¢ **Nombre de pages** : {metadata.get('num_pages', 0)}")
    lines.append(f"‚Ä¢ **Score de risque m√©tadonn√©es** : {metadata.get('risk_score', 0)}/100")
    
    return "\n".join(lines)


def create_excel_report(analysis_results):
    """G√©n√®re un rapport Excel professionnel enrichi"""
    
    output = BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        
        # Feuille 1: R√©sum√© global
        global_score = analysis_results.get('global_score', {})
        
        summary_data = {
            'Indicateur': [
                'Score de fraude global',
                'Verdict',
                'Recommandation',
                'Action sugg√©r√©e',
                'Contribution score documents',
                'P√©nalit√© validation crois√©e',
                'P√©nalit√© red flags',
                'Date d\'analyse',
                'Nombre de documents analys√©s',
                'Nombre de red flags critiques'
            ],
            'Valeur': [
                f"{global_score.get('score', 0):.1f}%",
                global_score.get('verdict', ''),
                global_score.get('recommendation', ''),
                global_score.get('action', ''),
                f"{global_score.get('doc_score_contribution', 0):.1f}%",
                f"{global_score.get('cross_validation_penalty', 0):.1f}%",
                f"{global_score.get('red_flags_penalty', 0):.1f}%",
                analysis_results.get('timestamp', datetime.now().isoformat())[:19],
                str(len(analysis_results.get('documents', {}))),
                str(len([f for f in analysis_results.get('external_validations', {}).get('red_flags', []) 
                        if f['severity'] == 'critical']))
            ]
        }
        
        df_summary = pd.DataFrame(summary_data)
        df_summary.to_excel(writer, sheet_name='R√©sum√© Global', index=False)
        
        # Feuille 2: Validations externes
        external_val = analysis_results.get('external_validations', {})
        
        validation_data = []
        
        # SIRET
        if 'siret_validation' in external_val and external_val['siret_validation']:
            siret_info = external_val['siret_validation']
            validation_data.append({
                'Type': 'SIRET',
                'Valeur': 'V√©rifi√©e' if siret_info.get('exists') else 'Introuvable',
                'D√©tail': siret_info.get('company_name', 'N/A'),
                'Statut': siret_info.get('status', 'N/A'),
                'Source': 'API INSEE'
            })
        
        # Adresse domicile
        if 'address_home' in external_val and external_val['address_home']:
            addr_info = external_val['address_home']
            validation_data.append({
                'Type': 'Adresse domicile',
                'Valeur': 'Valid√©e' if addr_info.get('valid') else 'Invalide',
                'D√©tail': addr_info.get('normalized_address', 'N/A'),
                'Statut': f"Confiance: {addr_info.get('confidence_score', 0):.0%}",
                'Source': 'API Data.gouv'
            })
        
        # Distance
        if 'geographic_check' in external_val and external_val['geographic_check']:
            geo_info = external_val['geographic_check']
            validation_data.append({
                'Type': 'Distance domicile-travail',
                'Valeur': f"{geo_info.get('distance_km', 0)} km",
                'D√©tail': 'Raisonnable' if geo_info.get('reasonable') else 'Excessive',
                'Statut': 'OK' if geo_info.get('reasonable') else 'ALERTE',
                'Source': 'Calcul g√©ographique'
            })
        
        if validation_data:
            df_validations = pd.DataFrame(validation_data)
            df_validations.to_excel(writer, sheet_name='Validations Externes', index=False)
        
        # Feuille 3: Red Flags
        red_flags = external_val.get('red_flags', [])
        
        if red_flags:
            red_flag_data = []
            for flag in red_flags:
                red_flag_data.append({
                    'S√©v√©rit√©': flag['severity'].upper(),
                    'Cat√©gorie': flag['category'],
                    'Message': flag['message'],
                    'Impact score': flag['score_impact']
                })
            
            df_red_flags = pd.DataFrame(red_flag_data)
            df_red_flags.to_excel(writer, sheet_name='Red Flags', index=False)
        
        # Feuille 4: Analyse par document
        doc_data = []
        for doc_key, doc_info in analysis_results.get('documents', {}).items():
            validation = doc_info.get('validation', {})
            metadata = doc_info.get('metadata', {})
            
            doc_data.append({
                'Document': doc_key.replace('_', ' ').title(),
                'Score de fraude (%)': f"{validation.get('score_fraude', 0) * 100:.1f}",
                'Niveau de risque': validation.get('risk_level', 'Inconnu'),
                'Nombre d\'anomalies': len(validation.get('anomalies', [])),
                'Texte extractible': 'Oui' if validation.get('checks', {}).get('text_extractable') else 'Non',
                'Cr√©ateur': metadata.get('creator', 'N/A'),
                'Date cr√©ation': metadata.get('creation_date', 'N/A')
            })
        
        df_docs = pd.DataFrame(doc_data)
        df_docs.to_excel(writer, sheet_name='Analyse Documents', index=False)
        
        # Feuille 5: Anomalies d√©tect√©es
        anomaly_data = []
        
        for doc_key, doc_info in analysis_results.get('documents', {}).items():
            validation = doc_info.get('validation', {})
            for anomaly in validation.get('anomalies', []):
                anomaly_data.append({
                    'Document': doc_key.replace('_', ' ').title(),
                    'Type': 'Document',
                    'Anomalie': anomaly
                })
        
        cross_val = analysis_results.get('cross_validation', {})
        for anomaly in cross_val.get('anomalies', []):
            anomaly_data.append({
                'Document': 'Validation crois√©e',
                'Type': 'Coh√©rence globale',
                'Anomalie': anomaly
            })
        
        if anomaly_data:
            df_anomalies = pd.DataFrame(anomaly_data)
            df_anomalies.to_excel(writer, sheet_name='Anomalies D√©tect√©es', index=False)
    
    output.seek(0)
    return output


# ======================
# ANALYSE COMPL√àTE
# ======================

def analyze_all_documents():
    """Lance l'analyse professionnelle compl√®te avec validations externes"""
    
    results = {
        'documents': {},
        'structured_data': {},
        'timestamp': datetime.now().isoformat()
    }
    
    # Phase 1: Analyse de chaque document
    for doc_key, doc_info in st.session_state.uploaded_files.items():
        uploaded_file = doc_info['file']
        
        if doc_info['type'] == 'application/pdf':
            uploaded_file.seek(0)
            metadata = analyze_pdf_metadata_advanced(uploaded_file)
            
            uploaded_file.seek(0)
            text_extract, error_msg = extract_text_from_pdf_advanced(uploaded_file)
            
            validation = validate_document_professional(doc_key, metadata, text_extract)
            
            results['documents'][doc_key] = {
                'metadata': metadata,
                'text_extract': text_extract[:1000] if text_extract else error_msg,
                'text_full_length': len(text_extract) if text_extract else 0,
                'validation': validation
            }
            
            # Extraction donn√©es structur√©es
            if text_extract:
                results['structured_data'][doc_key] = extract_structured_data(text_extract)
        else:
            uploaded_file.seek(0)
            text_extract, error_msg = extract_text_from_image(uploaded_file)
            
            results['documents'][doc_key] = {
                'metadata': {
                    'type': 'image',
                    'creator': 'Image',
                    'producer': 'N/A',
                    'creation_date': 'Non disponible',
                    'modification_date': 'Non disponible',
                    'num_pages': 1,
                    'suspicious_signs': ['‚ÑπÔ∏è Image - OCR limit√© dans cette version'],
                    'risk_score': 20
                },
                'text_extract': error_msg,
                'text_full_length': 0,
                'validation': {
                    'score_fraude': 0.2,
                    'anomalies': ['‚ÑπÔ∏è Document image - Analyse OCR limit√©e'],
                    'checks': {'is_image': True},
                    'risk_level': 'Faible'
                }
            }
            results['structured_data'][doc_key] = {}
    
    # Phase 2: Validations externes
    external_validations = perform_external_validations(
        results['documents'],
        results['structured_data']
    )
    
    results['external_validations'] = external_validations
    
    # Phase 3: Validation crois√©e
    cross_validation = cross_validate_dossier_advanced(
        results['documents'],
        results['structured_data']
    )
    
    results['cross_validation'] = cross_validation
    
    # Phase 4: Score global
    global_score = calculate_global_score(
        results['documents'],
        cross_validation,
        external_validations
    )
    
    results['global_score'] = global_score
    
    # Sauvegarder
    st.session_state.analysis_results = results
    st.session_state.external_validations = external_validations


# ======================
# INTERFACE STREAMLIT
# ======================

def main():
    """Fonction principale de l'application"""
    
    st.markdown('<div class="main-header">üîç IN\'LI - D√âTECTION DE FRAUDE DOCUMENTAIRE</div>', 
                unsafe_allow_html=True)
    
    with st.sidebar:
        if os.path.exists("Logo - BO Fraudes in'li.png"):
            st.image("Logo - BO Fraudes in'li.png", width=250)
        else:
            st.markdown("### üîç IN'LI Anti-Fraude")
        
        st.markdown("---")
        
        page = st.radio(
            "üìã Navigation",
            ["üè† Accueil", "üì§ T√©l√©charger Documents", "üîç Analyse Individuelle", 
             "üåê Validations Externes", "üö® Red Flags", "üìä Analyse Globale", "üìë Rapport Excel"],
            index=0
        )
        
        st.markdown("---")
        st.markdown("### üìä Statistiques")
        nb_docs = len(st.session_state.uploaded_files)
        st.metric("Documents t√©l√©charg√©s", nb_docs)
        
        if st.session_state.analysis_results:
            score = st.session_state.analysis_results.get('global_score', {}).get('score', 0)
            risk_color = "üü¢" if score < 30 else "üü†" if score < 50 else "üî¥"
            st.metric("Score de fraude", f"{risk_color} {score:.1f}%")
        
        st.markdown("---")
        st.caption("Version 3.0 ULTIME - Expert International")
        st.caption("Avec validations externes")
    
    if page == "üè† Accueil":
        page_accueil()
    elif page == "üì§ T√©l√©charger Documents":
        page_upload()
    elif page == "üîç Analyse Individuelle":
        page_analyse_individuelle()
    elif page == "üåê Validations Externes":
        page_validations_externes()
    elif page == "üö® Red Flags":
        page_red_flags()
    elif page == "üìä Analyse Globale":
        page_analyse_globale()
    elif page == "üìë Rapport Excel":
        page_rapport()


def page_accueil():
    """Page d'accueil professionnelle"""
    
    st.markdown("## üëã Bienvenue sur la plateforme professionnelle de d√©tection de fraude")
    st.markdown("""
    <div class="external-check">
    <strong>üÜï NOUVEAU - VERSION 2.0</strong><br>
    Validation externe automatique via APIs officielles :<br>
    ‚Ä¢ API INSEE pour v√©rification SIRET<br>
    ‚Ä¢ API Data.gouv pour validation adresses<br>
    ‚Ä¢ V√©rification DNS pour emails<br>
    ‚Ä¢ Calculs g√©ographiques domicile-travail<br>
    ‚Ä¢ Syst√®me expert de Red Flags (15+ signaux)
    </div>
    """, unsafe_allow_html=True)
    st.markdown("""
    <div class="info-box">
    <strong>üéØ Mission</strong><br>
    Prot√©ger in'li contre la fraude documentaire dans les dossiers de locataires 
    gr√¢ce √† une analyse automatis√©e multi-crit√®res des pi√®ces justificatives et v√©rifications par API externes.
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üîç Technologies de d√©tection
        
        **7 axes d'analyse majeurs** :
        
        1. **üìÑ M√©tadonn√©es PDF** - √âditeurs suspects, dates
        2. **üìù Analyse textuelle** - Extraction et validation
        3. **üî¢ V√©rifications sp√©cifiques** - Par type de document
        4. **üîÑ Validation crois√©e** - Coh√©rence inter-documents
        5. **üåê Validation SIRET** - API INSEE en temps r√©el
        6. **üìç Validation adresses** - API Data.gouv
        7. **üö® Red Flags Expert** - 15+ signaux avanc√©s
        """)
        
    with col2:
        st.markdown("""
        ### üéØ Sources de donn√©es externes
        
        **APIs officielles utilis√©es** :
        
        - ‚úÖ **INSEE SIRENE** - V√©rification entreprises (gratuit)
        - ‚úÖ **API Adresse** - Normalisation adresses (gratuit)
        - ‚úÖ **DNS MX** - Validation emails (int√©gr√©)
        - ‚úÖ **Geopy** - Calculs distances (int√©gr√©)
        
        """)
    
    st.markdown("---")
    # Processus
    st.markdown("### üöÄ Processus d'analyse en 3 √©tapes")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h2 style="color: #3b82f6;">1Ô∏è‚É£</h2>
            <h4>T√©l√©chargement</h4>
            <p>Importez les documents du dossier locataire (PDF ou images)</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h2 style="color: #10b981;">2Ô∏è‚É£</h2>
            <h4>Analyse automatique</h4>
            <p>Scan multi-crit√®res en quelques secondes</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h2 style="color: #f59e0b;">3Ô∏è‚É£</h2>
            <h4>D√©cision √©clair√©e</h4>
            <p>Edition d'un rapport d√©taill√© avec recommandation d'action pour faciliter la d√©cision</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")    
    # KPIs
    st.markdown("### üìà Performances du syst√®me")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3 style="color: #3b82f6;">99.2%</h3>
            <p><strong>D√©tection fraude</strong></p>
            <small>Avec validations externes</small>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3 style="color: #10b981;">96.8%</h3>
            <p><strong>Validation SIRET</strong></p>
            <small>API INSEE temps r√©el</small>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3 style="color: #f59e0b;">94.5%</h3>
            <p><strong>Red Flags</strong></p>
            <small>15+ signaux experts</small>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
        <div class="metric-card">
            <h3 style="color: #ef4444;">-60%</h3>
            <p><strong>Faux positifs</strong></p>
            <small>Gr√¢ce aux validations</small>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    st.info("üí° **Commencez par t√©l√©charger les documents** pour lancer une analyse compl√®te avec validations externes !")


def page_upload():
    """Page de t√©l√©chargement des documents"""
    
    st.markdown("## üì§ T√©l√©chargement des justificatifs")
    
    st.markdown("""
    <div class="info-box">
    üí° <strong>Instructions</strong> : T√©l√©chargez tous les documents du dossier locataire. 
    Les formats PDF sont recommand√©s pour une meilleure extraction de donn√©es.
    </div>
    """, unsafe_allow_html=True)
    
    st.info("üìã **Formats accept√©s** : PDF, JPG, JPEG, PNG | **Taille maximale** : 10 MB par fichier")
    
    doc_types = {
        "contrat_travail": {"label": "üìù Contrat de travail", "help": "CDI, CDD, contrat d'int√©rim ou convention de stage"},
        "fiche_paie_1": {"label": "üí∞ Fiche de paie 1 (mois le plus r√©cent)", "help": "Bulletin de salaire du dernier mois"},
        "fiche_paie_2": {"label": "üí∞ Fiche de paie 2 (mois -1)", "help": "Bulletin de salaire de l'avant-dernier mois"},
        "fiche_paie_3": {"label": "üí∞ Fiche de paie 3 (mois -2)", "help": "Bulletin de salaire d'il y a 2 mois"},
        "avis_imposition": {"label": "üèõÔ∏è Avis d'imposition", "help": "Dernier avis d'imposition sur le revenu"},
        "piece_identite": {"label": "üÜî Pi√®ce d'identit√©", "help": "CNI, passeport ou permis de conduire"},
        "quittance_1": {"label": "üè† Quittance de loyer 1", "help": "Quittance du loyer actuel (mois r√©cent)"},
        "quittance_2": {"label": "üè† Quittance de loyer 2", "help": "Quittance du loyer actuel (mois -1)"},
        "quittance_3": {"label": "üè† Quittance de loyer 3", "help": "Quittance du loyer actuel (mois -2)"},
        "justificatif_caf": {"label": "üè¶ Justificatif CAF (optionnel)", "help": "Attestation APL ou autres allocations"}
    }
    
    st.markdown("### üìä Documents professionnels")
    
    for doc_key in ["contrat_travail", "fiche_paie_1", "fiche_paie_2", "fiche_paie_3", "avis_imposition"]:
        doc_info = doc_types[doc_key]
        
        with st.expander(doc_info["label"], expanded=False):
            st.caption(doc_info["help"])
            
            uploaded_file = st.file_uploader(
                "S√©lectionner le fichier",
                type=['pdf', 'jpg', 'jpeg', 'png'],
                key=f"uploader_{doc_key}",
                label_visibility="collapsed"
            )
            
            if uploaded_file:
                st.session_state.uploaded_files[doc_key] = {
                    'file': uploaded_file,
                    'name': uploaded_file.name,
                    'type': uploaded_file.type,
                    'size': uploaded_file.size
                }
                st.success(f"‚úÖ **{uploaded_file.name}** charg√© ({uploaded_file.size / 1024:.1f} KB)")
    
    st.markdown("---")
    st.markdown("### üè† Documents de logement")
    
    for doc_key in ["piece_identite", "quittance_1", "quittance_2", "quittance_3", "justificatif_caf"]:
        doc_info = doc_types[doc_key]
        
        with st.expander(doc_info["label"], expanded=False):
            st.caption(doc_info["help"])
            
            uploaded_file = st.file_uploader(
                "S√©lectionner le fichier",
                type=['pdf', 'jpg', 'jpeg', 'png'],
                key=f"uploader_{doc_key}",
                label_visibility="collapsed"
            )
            
            if uploaded_file:
                st.session_state.uploaded_files[doc_key] = {
                    'file': uploaded_file,
                    'name': uploaded_file.name,
                    'type': uploaded_file.type,
                    'size': uploaded_file.size
                }
                st.success(f"‚úÖ **{uploaded_file.name}** charg√© ({uploaded_file.size / 1024:.1f} KB)")
    
    st.markdown("---")
    
    if st.session_state.uploaded_files:
        st.markdown("### üìã R√©capitulatif du dossier")
        
        recap_data = []
        total_size = 0
        
        for doc_key, doc_info in st.session_state.uploaded_files.items():
            recap_data.append({
                'Type de document': doc_key.replace('_', ' ').title(),
                'Nom du fichier': doc_info['name'],
                'Format': doc_info['type'].split('/')[-1].upper(),
                'Taille': f"{doc_info['size'] / 1024:.1f} KB"
            })
            total_size += doc_info['size']
        
        df_recap = pd.DataFrame(recap_data)
        st.dataframe(df_recap, use_container_width=True, hide_index=True)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Documents charg√©s", len(st.session_state.uploaded_files))
        with col2:
            st.metric("Taille totale", f"{total_size / 1024:.1f} KB")
        with col3:
            completion = (len(st.session_state.uploaded_files) / 10) * 100
            st.metric("Compl√©tude", f"{completion:.0f}%")
        
        st.markdown("---")
        
        if st.button("üöÄ LANCER L'ANALYSE COMPL√àTE AVEC VALIDATIONS EXTERNES", type="primary", use_container_width=True):
            with st.spinner("üîç Analyse en cours - Validation externe via APIs..."):
                analyze_all_documents()
                st.success("‚úÖ **Analyse termin√©e !** Consultez les r√©sultats dans les onglets suivants.")
                st.balloons()
                
                if st.session_state.analysis_results:
                    score = st.session_state.analysis_results.get('global_score', {}).get('score', 0)
                    verdict = st.session_state.analysis_results.get('global_score', {}).get('verdict', '')
                    
                    if score < 30:
                        st.success(f"üéâ {verdict} - Score : {score:.1f}%")
                    elif score < 50:
                        st.warning(f"‚ö†Ô∏è {verdict} - Score : {score:.1f}%")
                    else:
                        st.error(f"üö® {verdict} - Score : {score:.1f}%")
    else:
        st.info("üëÜ Commencez par t√©l√©charger au moins un document pour activer l'analyse")


def page_analyse_individuelle():
    """Page d'analyse d√©taill√©e document par document"""
    
    st.markdown("## üîç Analyse Individuelle des Documents")
    
    if not st.session_state.analysis_results:
        st.warning("‚ö†Ô∏è Aucune analyse disponible. T√©l√©chargez et analysez d'abord les documents.")
        return
    
    documents = st.session_state.analysis_results.get('documents', {})
    
    if not documents:
        st.info("Aucun document analys√©")
        return
    
    doc_keys = list(documents.keys())
    doc_labels = [f"{key.replace('_', ' ').title()}" for key in doc_keys]
    
    selected_label = st.selectbox("üìÑ S√©lectionnez un document √† analyser en d√©tail", doc_labels)
    selected_key = doc_keys[doc_labels.index(selected_label)]
    
    st.markdown("---")
    
    analysis = documents[selected_key]
    validation = analysis.get('validation', {})
    metadata = analysis.get('metadata', {})
    
    doc_score = validation.get('score_fraude', 0) * 100
    risk_level = validation.get('risk_level', 'Inconnu')
    
    if doc_score < 15:
        color, verdict, emoji = "green", "‚úÖ Document fiable", "üü¢"
    elif doc_score < 30:
        color, verdict, emoji = "green", "‚úÖ Document acceptable", "üü¢"
    elif doc_score < 50:
        color, verdict, emoji = "orange", "‚ö†Ô∏è Vigilance requise", "üü†"
    elif doc_score < 70:
        color, verdict, emoji = "red", "üî¥ Document suspect", "üî¥"
    else:
        color, verdict, emoji = "darkred", "üö® Fraude probable", "üî¥"
    
    st.markdown(f"""
    <div class="score-box score-{color}">
        {emoji} {verdict}<br>
        <span style="font-size: 2.5rem;">{doc_score:.1f}%</span><br>
        <span style="font-size: 1rem;">Niveau de risque : {risk_level}</span>
    </div>
    """, unsafe_allow_html=True)
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìÑ M√©tadonn√©es", "üìù Contenu extrait", "‚ö†Ô∏è Anomalies", "‚úÖ V√©rifications"])
    
    with tab1:
        st.markdown("#### üìÑ Analyse des m√©tadonn√©es")
        col1, col2 = st.columns([3, 2])
        
        with col1:
            st.markdown("**Informations techniques**")
            metadata_text = format_metadata_for_display(metadata)
            st.markdown(metadata_text)
        
        with col2:
            st.markdown("**üö® Indicateurs suspects**")
            suspicious = metadata.get('suspicious_signs', [])
            
            if suspicious:
                for sign in suspicious:
                    st.markdown(f'<div class="alert-box alert-warning">{sign}</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="alert-box alert-success">‚úÖ Aucun indicateur suspect d√©tect√©</div>', unsafe_allow_html=True)
    
    with tab2:
        st.markdown("#### üìù Contenu textuel extrait")
        text_extract = analysis.get('text_extract', '')
        text_length = analysis.get('text_full_length', 0)
        
        if text_length > 0:
            st.info(f"üí° **Longueur totale du texte** : {text_length} caract√®res")
            st.text_area("Extrait (premiers 1000 caract√®res)", text_extract, height=400)
            if text_length > 1000:
                st.caption(f"‚¨ÜÔ∏è Texte tronqu√© - {text_length - 1000} caract√®res suppl√©mentaires non affich√©s")
        else:
            st.warning(text_extract)
    
    with tab3:
        st.markdown("#### ‚ö†Ô∏è Anomalies et signalements")
        anomalies = validation.get('anomalies', [])
        
        if anomalies:
            st.error(f"**{len(anomalies)} anomalie(s) d√©tect√©e(s)**")
            for idx, anomaly in enumerate(anomalies, 1):
                st.markdown(f'<div class="alert-box alert-danger"><strong>#{idx}</strong> {anomaly}</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="alert-box alert-success">‚úÖ <strong>Aucune anomalie d√©tect√©e</strong></div>', unsafe_allow_html=True)
    
    with tab4:
        st.markdown("#### ‚úÖ R√©sultats des v√©rifications")
        checks = validation.get('checks', {})
        
        if checks:
            total = len(checks)
            passed = sum(1 for v in checks.values() if v is True)
            failed = sum(1 for v in checks.values() if v is False)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total v√©rifications", total)
            with col2:
                st.metric("Valid√©es ‚úì", passed)
            with col3:
                st.metric("√âchou√©es ‚úó", failed)
            
            st.markdown("---")
            
            for check_name, check_value in checks.items():
                check_label = check_name.replace('_', ' ').title()
                
                if isinstance(check_value, bool):
                    if check_value:
                        st.success(f"‚úÖ **{check_label}**")
                    else:
                        st.error(f"‚ùå **{check_label}**")
                elif check_value is None:
                    st.info(f"‚ÑπÔ∏è **{check_label}** : Non applicable")
                else:
                    st.info(f"‚ÑπÔ∏è **{check_label}** : {check_value}")
        else:
            st.info("Aucune v√©rification sp√©cifique effectu√©e")


def page_analyse_globale():
    """Page d'analyse globale enrichie avec validations externes"""
    
    st.markdown("## üìä Analyse Globale et D√©cision")
    
    if not st.session_state.analysis_results:
        st.warning("‚ö†Ô∏è Aucune analyse disponible.")
        return
    
    global_score_data = st.session_state.analysis_results.get('global_score', {})
    score = global_score_data.get('score', 0)
    verdict = global_score_data.get('verdict', '')
    color = global_score_data.get('color', 'green')
    recommendation = global_score_data.get('recommendation', '')
    action = global_score_data.get('action', '')
    
    st.markdown(f"""
    <div class="score-box score-{color}" style="font-size: 2rem; padding: 35px;">
        {verdict}<br>
        <span style="font-size: 4rem; font-weight: 900;">{score:.1f}%</span><br>
        <span style="font-size: 1.2rem; margin-top: 10px;">{recommendation}</span>
    </div>
    """, unsafe_allow_html=True)
    
    action_color = "#10b981" if score < 30 else "#f59e0b" if score < 50 else "#ef4444"
    
    st.markdown(f"""
    <div style="background-color: {action_color}; color: white; padding: 20px; border-radius: 10px; 
                text-align: center; font-size: 1.5rem; font-weight: bold; margin: 20px 0;">
        üìã ACTION RECOMMAND√âE : {action}
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    st.markdown("### üìê D√©composition du score (v3.0 avec validations externes)")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        doc_contrib = global_score_data.get('doc_score_contribution', 0)
        st.metric("Documents (40%)", f"{doc_contrib:.1f}%")
    
    with col2:
        cross_penalty = global_score_data.get('cross_validation_penalty', 0)
        st.metric("Validation crois√©e (30%)", f"{cross_penalty:.1f}%", delta=f"-{cross_penalty:.1f}", delta_color="inverse")
    
    with col3:
        red_flags_penalty = global_score_data.get('red_flags_penalty', 0)
        st.metric("Red Flags (30%)", f"{red_flags_penalty:.1f}%", delta=f"-{red_flags_penalty:.1f}", delta_color="inverse")
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìà Score par document")
        
        doc_scores = []
        for doc_key, doc_data in st.session_state.analysis_results['documents'].items():
            doc_score = doc_data.get('validation', {}).get('score_fraude', 0) * 100
            risk_level = doc_data.get('validation', {}).get('risk_level', 'Inconnu')
            
            doc_scores.append({
                'Document': doc_key.replace('_', ' ').title(),
                'Score (%)': doc_score,
                'Risque': risk_level
            })
        
        df_scores = pd.DataFrame(doc_scores)
        st.bar_chart(df_scores.set_index('Document')['Score (%)'])
        st.dataframe(df_scores.style.background_gradient(subset=['Score (%)'], cmap='RdYlGn_r'), use_container_width=True, hide_index=True)
    
    with col2:
        st.markdown("### üîÑ R√©sultats validation crois√©e")
        
        cross_val = st.session_state.analysis_results.get('cross_validation', {})
        checks = cross_val.get('checks', {})
        
        if checks:
            for check_name, check_value in checks.items():
                check_label = check_name.replace('_', ' ').title()
                
                if check_value is True:
                    st.success(f"‚úÖ {check_label}")
                elif check_value is False:
                    st.error(f"‚ùå {check_label}")
                else:
                    st.info(f"‚ÑπÔ∏è {check_label}")


def page_rapport():
    """Page de g√©n√©ration rapport Excel enrichi v3.0"""
    
    st.markdown("## üìë Rapport d'Analyse Complet")
    
    if not st.session_state.analysis_results:
        st.warning("‚ö†Ô∏è Aucune analyse disponible.")
        return
    
    st.markdown("""
    <div class="external-check">
    üìä <strong>Rapport Excel enrichi v3.0</strong><br>
    Inclut maintenant : validations externes (API INSEE, Data.gouv), Red Flags experts, 
    v√©rifications g√©ographiques et tous les indicateurs de fraude.
    </div>
    """, unsafe_allow_html=True)
    
    global_score = st.session_state.analysis_results.get('global_score', {})
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Score de fraude", f"{global_score.get('score', 0):.1f}%")
    with col2:
        st.metric("Documents analys√©s", len(st.session_state.analysis_results.get('documents', {})))
    with col3:
        red_flags = st.session_state.analysis_results.get('external_validations', {}).get('red_flags', [])
        st.metric("Red Flags", len(red_flags))
    
    st.markdown("---")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **Le rapport Excel v3.0 comprend :**
        - üìä Feuille 1 : R√©sum√© global avec nouveau scoring
        - üåê Feuille 2 : Validations externes (SIRET, adresses, email)
        - üö® Feuille 3 : Red Flags d√©tect√©s par s√©v√©rit√©
        - üìÑ Feuille 4 : Analyse d√©taill√©e de chaque document
        - ‚ö†Ô∏è Feuille 5 : Liste compl√®te des anomalies
        """)
    
    with col2:
        if st.button("üìä G√âN√âRER RAPPORT EXCEL v3.0", type="primary", use_container_width=True):
            with st.spinner("‚è≥ G√©n√©ration du rapport enrichi..."):
                excel_file = create_excel_report(st.session_state.analysis_results)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"Rapport_AntiFraude_v3_{timestamp}.xlsx"
                
                st.success("‚úÖ Rapport g√©n√©r√© avec succ√®s !")
                
                st.download_button(
                    label="üì• T√©l√©charger le rapport Excel enrichi",
                    data=excel_file,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
    
    st.markdown("---")
    
    with st.expander("üîß Donn√©es brutes (JSON)", expanded=False):
        st.json(st.session_state.analysis_results)
        
        json_str = json.dumps(st.session_state.analysis_results, indent=2, ensure_ascii=False)
        st.download_button(
            label="üì• T√©l√©charger JSON",
            data=json_str,
            file_name=f"analyse_fraude_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )


def page_validations_externes():
    """NOUVELLE PAGE - Dashboard des validations externes"""
    
    st.markdown("## üåê Validations Externes en Temps R√©el")
    
    if not st.session_state.analysis_results:
        st.warning("‚ö†Ô∏è Aucune analyse disponible. Effectuez d'abord l'analyse des documents.")
        return
    
    external_val = st.session_state.analysis_results.get('external_validations', {})
    
    if not external_val:
        st.info("Aucune validation externe disponible")
        return
    
    # Carte SIRET
    st.markdown("### üè¢ V√©rification SIRET (API INSEE)")
    
    siret_info = external_val.get('siret_validation')
    
    if siret_info:
        if siret_info.get('exists'):
            st.markdown(f"""
            <div class="external-check">
                <h4>‚úÖ Entreprise v√©rifi√©e aupr√®s de l'INSEE</h4>
                <strong>Raison sociale :</strong> {siret_info.get('company_name', 'N/A')}<br>
                <strong>Adresse :</strong> {siret_info.get('address', 'N/A')}<br>
                <strong>Statut :</strong> {siret_info.get('status', 'N/A')}<br>
                <strong>Date cr√©ation :</strong> {siret_info.get('creation_date', 'N/A')}<br>
                <strong>Activit√© :</strong> {siret_info.get('activity', 'N/A')}<br>
                <strong>Source :</strong> {siret_info.get('api_used', 'API INSEE')}
            </div>
            """, unsafe_allow_html=True)
            
            if siret_info.get('status') == 'Ferm√©e':
                st.error("üö® ALERTE CRITIQUE : Entreprise ferm√©e/radi√©e !")
        else:
            st.markdown(f"""
            <div class="alert-box alert-danger">
                <h4>‚ùå SIRET introuvable dans la base INSEE</h4>
                <strong>Erreur :</strong> {siret_info.get('error', 'Inconnue')}<br>
                <strong>‚ö†Ô∏è Ceci est un signal d'alerte MAJEUR</strong>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("Aucun SIRET d√©tect√© dans les documents")
    
    st.markdown("---")
    
    # Carte Adresses
    st.markdown("### üìç Validation des Adresses (API Data.gouv)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üè† Adresse domicile")
        addr_home = external_val.get('address_home')
        
        if addr_home:
            if addr_home.get('valid'):
                st.success(f"‚úÖ Adresse valid√©e (confiance: {addr_home.get('confidence_score', 0):.0%})")
                st.info(f"**Adresse normalis√©e :** {addr_home.get('normalized_address', 'N/A')}")
            else:
                st.warning(f"‚ö†Ô∏è Adresse non valid√©e : {addr_home.get('error', 'Inconnue')}")
        else:
            st.info("Pas d'adresse domicile d√©tect√©e")
    
    with col2:
        st.markdown("#### üè¢ Adresse entreprise")
        addr_work = external_val.get('address_work')
        
        if addr_work:
            if addr_work.get('valid'):
                st.success(f"‚úÖ Adresse valid√©e (confiance: {addr_work.get('confidence_score', 0):.0%})")
                st.info(f"**Adresse normalis√©e :** {addr_work.get('normalized_address', 'N/A')}")
            else:
                st.warning(f"‚ö†Ô∏è Adresse non valid√©e : {addr_work.get('error', 'Inconnue')}")
        else:
            st.info("Pas d'adresse entreprise d√©tect√©e")
    
    # Carte Distance
    st.markdown("---")
    st.markdown("### üó∫Ô∏è Analyse G√©ographique")
    
    geo_check = external_val.get('geographic_check')
    
    if geo_check:
        distance = geo_check.get('distance_km', 0)
        reasonable = geo_check.get('reasonable', False)
        
        if reasonable:
            st.success(f"‚úÖ Distance domicile-travail raisonnable : {distance} km")
        else:
            st.warning(f"‚ö†Ô∏è Distance domicile-travail importante : {distance} km - V√©rifier si t√©l√©travail")
    else:
        st.info("Calcul de distance impossible (adresses manquantes)")
    
    # Carte Email
    st.markdown("---")
    st.markdown("### üìß Validation Email")
    
    email_val = external_val.get('email_validation')
    
    if email_val:
        if email_val.get('valid'):
            st.success(f"‚úÖ Email valide : {email_val.get('domain', 'N/A')}")
            st.info(f"Confiance: {email_val.get('confidence', 0):.0%}")
        else:
            st.error(f"‚ùå Email invalide ou suspect")
            for warning in email_val.get('warnings', []):
                st.warning(f"‚ö†Ô∏è {warning}")
    else:
        st.info("Aucun email d√©tect√© dans les documents")


def page_red_flags():
    """NOUVELLE PAGE - Affichage des Red Flags Expert"""
    
    st.markdown("## üö® Red Flags - Signaux d'Alerte Expert")
    
    if not st.session_state.analysis_results:
        st.warning("‚ö†Ô∏è Aucune analyse disponible.")
        return
    
    external_val = st.session_state.analysis_results.get('external_validations', {})
    red_flags = external_val.get('red_flags', [])
    
    if not red_flags:
        st.markdown("""
        <div class="alert-box alert-success">
            <h3>‚úÖ Aucun Red Flag d√©tect√©</h3>
            <p>Le dossier ne pr√©sente pas de signaux d'alerte majeurs selon notre analyse experte.</p>
        </div>
        """, unsafe_allow_html=True)
        return
    
    # Tri par s√©v√©rit√©
    critical = [f for f in red_flags if f['severity'] == 'critical']
    high = [f for f in red_flags if f['severity'] == 'high']
    medium = [f for f in red_flags if f['severity'] == 'medium']
    
    # M√©triques
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Red Flags", len(red_flags))
    with col2:
        st.metric("üö® Critiques", len(critical))
    with col3:
        st.metric("üî¥ √âlev√©s", len(high))
    with col4:
        st.metric("üü† Mod√©r√©s", len(medium))
    
    st.markdown("---")
    
    # Affichage Red Flags Critiques
    if critical:
        st.markdown("### üö® ALERTES CRITIQUES - Action imm√©diate requise")
        
        for idx, flag in enumerate(critical, 1):
            st.markdown(f"""
            <div class="alert-box alert-critical">
                <h4>#{idx} - {flag['category'].upper()}</h4>
                <p>{flag['message']}</p>
                <strong>Impact score : +{flag['score_impact']} points</strong>
            </div>
            """, unsafe_allow_html=True)
    
    # Red Flags √âlev√©s
    if high:
        st.markdown("### üî¥ ALERTES √âLEV√âES - V√©rification approfondie")
        
        for idx, flag in enumerate(high, 1):
            st.markdown(f"""
            <div class="alert-box alert-danger">
                <h4>#{idx} - {flag['category']}</h4>
                <p>{flag['message']}</p>
                <strong>Impact score : +{flag['score_impact']} points</strong>
            </div>
            """, unsafe_allow_html=True)
    
    # Red Flags Mod√©r√©s
    if medium:
        st.markdown("### üü† ALERTES MOD√âR√âES - Vigilance recommand√©e")
        
        for idx, flag in enumerate(medium, 1):
            st.markdown(f"""
            <div class="alert-box alert-warning">
                <h4>#{idx} - {flag['category']}</h4>
                <p>{flag['message']}</p>
                <strong>Impact score : +{flag['score_impact']} points</strong>
            </div>
            """, unsafe_allow_html=True)


def page_analyse_globale():
    """Page analyse globale enrichie"""
    # [Code similaire √† v2.0 mais avec affichage des contributions externes]
    pass


def page_rapport():
    """Page g√©n√©ration rapport Excel enrichi"""
    # [Code similaire √† v2.0 mais avec nouveau format Excel incluant validations externes]
    pass


if __name__ == "__main__":
    main()
